{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN89WfqY2jKBPsFYN7iGGtp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"id":"b3CzYHTpPeHa","executionInfo":{"status":"ok","timestamp":1712050170971,"user_tz":-60,"elapsed":232,"user":{"displayName":"mo na","userId":"16790052438334414608"}}},"outputs":[],"source":["def encode_split_and_scale_data(df):\n","\n","  # Convert categorical labels to numerical labels\n","  label_encoder = LabelEncoder()\n","  df['status_encoded'] = label_encoder.fit_transform(df['Status'])\n","\n","  # Convert numerical labels to one-hot encoded format\n","  encoded_status = to_categorical(df['status_encoded'])\n","\n","  # Split the preprocessed data into our features and target arrays\n","  # Features\n","  X = df.drop(columns=['Status', 'status_encoded'])\n","  # Target variable\n","  y = encoded_status\n","\n","  #print(f\"encoded status: \\n{y[121:150]}\")\n","  #print(f\"original status: \\n{df['Status'][121:150]}\")\n","\n","  # Split the preprocessed data into a training and testing dataset\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n","\n","  # Create a StandardScaler instance\n","  scaler = StandardScaler()\n","\n","  # Fit the StandardScaler\n","  X_train_scaled = scaler.fit_transform(X_train)\n","  X_test_scaled = scaler.transform(X_test)\n","\n","  return  X_train_scaled, X_test_scaled, y_train, y_test"]},{"cell_type":"code","source":["def define_and_fit_nn_model(X_train_scaled, X_test_scaled, y_train, y_test, num_layers, num_neurons, activation_function,num_epochs):\n","\n","    # Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n","    input_features = X_train_scaled.shape[1]\n","    print(f\"Input features: {input_features}\")\n","\n","    nn = tf.keras.models.Sequential()\n","\n","    # Add the input layer\n","    nn.add(tf.keras.layers.Dense(units=num_neurons, input_dim=input_features, activation=activation_function))\n","\n","    # Add additional hidden layers\n","    for _ in range(num_layers-1):\n","        nn.add(tf.keras.layers.Dense(units=num_neurons, activation=activation_function))\n","        print(\"Adding layer\")\n","\n","    # Add the output layer\n","    nn.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n","\n","    # Check the structure of the model\n","    nn.summary()\n","\n","    # Compile the model\n","    nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","    # Train the model\n","    fit_model = nn.fit(X_train_scaled, y_train, epochs=num_epochs)\n","\n","    # Evaluate the model using the test data\n","    model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n","    print(f\"\\n Test Data Loss: {model_loss}, Test Data Accuracy: {model_accuracy}\")\n","\n","    return nn\n"],"metadata":{"id":"RNc_wMX-SKoy","executionInfo":{"status":"ok","timestamp":1712052121356,"user_tz":-60,"elapsed":266,"user":{"displayName":"mo na","userId":"16790052438334414608"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def nn_predict(nn,y_test,X_test_scaled):\n","\n","   test_range = range(85,90)\n","   print(f\"\\n test input:  \\n{y_test[test_range]}\")\n","   print(f\"\\n test output: \\n{nn.predict(X_test_scaled[test_range])}\")"],"metadata":{"id":"zo0n-TyaQDf4","executionInfo":{"status":"ok","timestamp":1712052606555,"user_tz":-60,"elapsed":248,"user":{"displayName":"mo na","userId":"16790052438334414608"}}},"execution_count":16,"outputs":[]}]}